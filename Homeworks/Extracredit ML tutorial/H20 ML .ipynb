{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# H20 ML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H2O is an open source, in-memory, distributed, fast, and scalable machine learning and predictive analytics platform that allows you to build machine learning models on big data and provides easy productionalization of those models in an enterprise environment.\n",
    "\n",
    "The speed, quality, ease-of-use, and model-deployment for the various cutting edge Supervised and Unsupervised algorithms like Deep Learning, Tree Ensembles, and GLRM make H2O a highly sought after API for big data data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install H2O\n",
    "\n",
    "Load the H2O Python module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start up the H2O Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM 18.3 (build 10.0.1+10, mixed mode)\n",
      "  Starting server from C:\\Users\\shiva\\Anaconda2\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: c:\\users\\shiva\\appdata\\local\\temp\\tmp8zsg6s\n",
      "  JVM stdout: c:\\users\\shiva\\appdata\\local\\temp\\tmp8zsg6s\\h2o_shiva_started_from_python.out\n",
      "  JVM stderr: c:\\users\\shiva\\appdata\\local\\temp\\tmp8zsg6s\\h2o_shiva_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>25 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_shiva_8791f9</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>8 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.15 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.2\n",
       "H2O cluster version age:    25 days\n",
       "H2O cluster name:           H2O_from_python_shiva_8791f9\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    8 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Algos, AutoML, Core V3, Core V4\n",
       "Python version:             2.7.15 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of threads, nthreads = -1, means use all cores on your machine\n",
    "# max_mem_size is the maximum memory (in GB) to allocate to H2O\n",
    "h2o.init(nthreads = -1, max_mem_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>23 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>25 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_shiva_8791f9</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>8 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.15 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O cluster uptime:         23 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.2\n",
       "H2O cluster version age:    25 days\n",
       "H2O cluster name:           H2O_from_python_shiva_8791f9\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    8 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Algos, AutoML, Core V3, Core V4\n",
       "Python version:             2.7.15 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(max_mem_size = 2)            #uses all cores by default\n",
    "h2o.remove_all()                          #clean slate, in case cluster was already running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the h2o package itself, we can use Python's builtin help() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package h2o:\n",
      "\n",
      "NAME\n",
      "    h2o - :mod:`h2o` -- module for using H2O services.\n",
      "\n",
      "FILE\n",
      "    c:\\users\\shiva\\anaconda2\\lib\\site-packages\\h2o\\__init__.py\n",
      "\n",
      "DESCRIPTION\n",
      "    (please add description).\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    assembly\n",
      "    astfun\n",
      "    automl (package)\n",
      "    backend (package)\n",
      "    cross_validation\n",
      "    demos\n",
      "    display\n",
      "    estimators (package)\n",
      "    exceptions\n",
      "    expr\n",
      "    expr_optimizer\n",
      "    frame\n",
      "    grid (package)\n",
      "    group_by\n",
      "    h2o\n",
      "    job\n",
      "    model (package)\n",
      "    schemas (package)\n",
      "    targetencoder\n",
      "    transforms (package)\n",
      "    tree (package)\n",
      "    two_dim_table\n",
      "    utils (package)\n",
      "\n",
      "SUBMODULES\n",
      "    __init__\n",
      "\n",
      "FUNCTIONS\n",
      "    api(endpoint, data=None, json=None, filename=None, save_to=None)\n",
      "        Perform a REST API request to a previously connected server.\n",
      "        \n",
      "        This function is mostly for internal purposes, but may occasionally be useful for direct access to\n",
      "        the backend H2O server. It has same parameters as :meth:`H2OConnection.request <h2o.backend.H2OConnection.request>`.\n",
      "    \n",
      "    as_list(data, use_pandas=True, header=True)\n",
      "        Convert an H2O data object into a python-specific object.\n",
      "        \n",
      "        WARNING! This will pull all data local!\n",
      "        \n",
      "        If Pandas is available (and use_pandas is True), then pandas will be used to parse the\n",
      "        data frame. Otherwise, a list-of-lists populated by character data will be returned (so\n",
      "        the types of data will all be str).\n",
      "        \n",
      "        :param data: an H2O data object.\n",
      "        :param use_pandas: If True, try to use pandas for reading in the data.\n",
      "        :param header: If True, return column names as first element in list\n",
      "        \n",
      "        :returns: List of lists (Rows x Columns).\n",
      "    \n",
      "    assign(data, xid)\n",
      "        (internal) Assign new id to the frame.\n",
      "        \n",
      "        :param data: an H2OFrame whose id should be changed\n",
      "        :param xid: new id for the frame.\n",
      "        :returns: the passed frame.\n",
      "    \n",
      "    cluster()\n",
      "        Return :class:`H2OCluster` object describing the backend H2O cloud.\n",
      "    \n",
      "    cluster_info(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().show_status()``.\n",
      "    \n",
      "    cluster_status(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().show_status(True)``.\n",
      "    \n",
      "    connect(server=None, url=None, ip=None, port=None, https=None, verify_ssl_certificates=None, auth=None, proxy=None, cookies=None, verbose=True, config=None)\n",
      "        Connect to an existing H2O server, remote or local.\n",
      "        \n",
      "        There are two ways to connect to a server: either pass a `server` parameter containing an instance of\n",
      "        an H2OLocalServer, or specify `ip` and `port` of the server that you want to connect to.\n",
      "        \n",
      "        :param server: An H2OLocalServer instance to connect to (optional).\n",
      "        :param url: Full URL of the server to connect to (can be used instead of `ip` + `port` + `https`).\n",
      "        :param ip: The ip address (or host name) of the server where H2O is running.\n",
      "        :param port: Port number that H2O service is listening to.\n",
      "        :param https: Set to True to connect via https:// instead of http://.\n",
      "        :param verify_ssl_certificates: When using https, setting this to False will disable SSL certificates verification.\n",
      "        :param auth: Either a (username, password) pair for basic authentication, or one of the requests.auth\n",
      "                     authenticator objects.\n",
      "        :param proxy: Proxy server address.\n",
      "        :param cookies: Cookie (or list of) to add to request\n",
      "        :param verbose: Set to False to disable printing connection status messages.\n",
      "        :param connection_conf: Connection configuration object encapsulating connection parameters.\n",
      "        :returns: the new :class:`H2OConnection` object.\n",
      "    \n",
      "    connection()\n",
      "        Return the current :class:`H2OConnection` handler.\n",
      "    \n",
      "    create_frame(frame_id=None, rows=10000, cols=10, randomize=True, real_fraction=None, categorical_fraction=None, integer_fraction=None, binary_fraction=None, time_fraction=None, string_fraction=None, value=0, real_range=100, factors=100, integer_range=100, binary_ones_fraction=0.02, missing_fraction=0.01, has_response=False, response_factors=2, positive_response=False, seed=None, seed_for_column_types=None)\n",
      "        Create a new frame with random data.\n",
      "        \n",
      "        Creates a data frame in H2O with real-valued, categorical, integer, and binary columns specified by the user.\n",
      "        \n",
      "        :param frame_id: the destination key. If empty, this will be auto-generated.\n",
      "        :param rows: the number of rows of data to generate.\n",
      "        :param cols: the number of columns of data to generate. Excludes the response column if has_response is True.\n",
      "        :param randomize: If True, data values will be randomly generated. This must be True if either\n",
      "            categorical_fraction or integer_fraction is non-zero.\n",
      "        :param value: if randomize is False, then all real-valued entries will be set to this value.\n",
      "        :param real_range: the range of randomly generated real values.\n",
      "        :param real_fraction: the fraction of columns that are real-valued.\n",
      "        :param categorical_fraction: the fraction of total columns that are categorical.\n",
      "        :param factors: the number of (unique) factor levels in each categorical column.\n",
      "        :param integer_fraction: the fraction of total columns that are integer-valued.\n",
      "        :param integer_range: the range of randomly generated integer values.\n",
      "        :param binary_fraction: the fraction of total columns that are binary-valued.\n",
      "        :param binary_ones_fraction: the fraction of values in a binary column that are set to 1.\n",
      "        :param time_fraction: the fraction of randomly created date/time columns.\n",
      "        :param string_fraction: the fraction of randomly created string columns.\n",
      "        :param missing_fraction: the fraction of total entries in the data frame that are set to NA.\n",
      "        :param has_response: A logical value indicating whether an additional response column should be prepended to the\n",
      "            final H2O data frame. If set to True, the total number of columns will be ``cols + 1``.\n",
      "        :param response_factors: if has_response is True, then this variable controls the type of the \"response\" column:\n",
      "            setting response_factors to 1 will generate real-valued response, any value greater or equal than 2 will\n",
      "            create categorical response with that many categories.\n",
      "        :param positive_reponse: when response variable is present and of real type, this will control whether it\n",
      "            contains positive values only, or both positive and negative.\n",
      "        :param seed: a seed used to generate random values when ``randomize`` is True.\n",
      "        :param seed_for_column_types: a seed used to generate random column types when ``randomize`` is True.\n",
      "        \n",
      "        :returns: an :class:`H2OFrame` object\n",
      "    \n",
      "    deep_copy(data, xid)\n",
      "        Create a deep clone of the frame ``data``.\n",
      "        \n",
      "        :param data: an H2OFrame to be cloned\n",
      "        :param xid: (internal) id to be assigned to the new frame.\n",
      "        :returns: new :class:`H2OFrame` which is the clone of the passed frame.\n",
      "    \n",
      "    demo(funcname, interactive=True, echo=True, test=False)\n",
      "        H2O built-in demo facility.\n",
      "        \n",
      "        :param funcname: A string that identifies the h2o python function to demonstrate.\n",
      "        :param interactive: If True, the user will be prompted to continue the demonstration after every segment.\n",
      "        :param echo: If True, the python commands that are executed will be displayed.\n",
      "        :param test: If True, `h2o.init()` will not be called (used for pyunit testing).\n",
      "        \n",
      "        :example:\n",
      "            >>> import h2o\n",
      "            >>> h2o.demo(\"gbm\")\n",
      "    \n",
      "    download_all_logs(dirname=u'.', filename=None)\n",
      "        Download H2O log files to disk.\n",
      "        \n",
      "        :param dirname: a character string indicating the directory that the log file should be saved in.\n",
      "        :param filename: a string indicating the name that the CSV file should be. Note that the saved format is .zip, so the file name must include the .zip extension.\n",
      "        \n",
      "        :returns: path of logs written in a zip file.\n",
      "        \n",
      "        :examples: The following code will save the zip file `'autoh2o_log.zip'` in a directory that is one down from where you are currently working into a directory called `your_directory_name`. (Please note that `your_directory_name` should be replaced with the name of the directory that you've created and that already exists.)\n",
      "        \n",
      "            >>> h2o.download_all_logs(dirname='./your_directory_name/', filename = 'autoh2o_log.zip')\n",
      "    \n",
      "    download_csv(data, filename)\n",
      "        Download an H2O data set to a CSV file on the local disk.\n",
      "        \n",
      "        Warning: Files located on the H2O server may be very large! Make sure you have enough\n",
      "        hard drive space to accommodate the entire file.\n",
      "        \n",
      "        :param data: an H2OFrame object to be downloaded.\n",
      "        :param filename: name for the CSV file where the data should be saved to.\n",
      "    \n",
      "    download_pojo(model, path=u'', get_jar=True, jar_name=u'')\n",
      "        Download the POJO for this model to the directory specified by path; if path is \"\", then dump to screen.\n",
      "        \n",
      "        :param model: the model whose scoring POJO should be retrieved.\n",
      "        :param path: an absolute path to the directory where POJO should be saved.\n",
      "        :param get_jar: retrieve the h2o-genmodel.jar also (will be saved to the same folder ``path``).\n",
      "        :param jar_name: Custom name of genmodel jar.\n",
      "        :returns: location of the downloaded POJO file.\n",
      "    \n",
      "    enable_expr_optimizations(flag)\n",
      "        Enable expression tree local optimizations.\n",
      "    \n",
      "    export_file(frame, path, force=False, parts=1)\n",
      "        Export a given H2OFrame to a path on the machine this python session is currently connected to.\n",
      "        \n",
      "        :param frame: the Frame to save to disk.\n",
      "        :param path: the path to the save point on disk.\n",
      "        :param force: if True, overwrite any preexisting file with the same path\n",
      "        :param parts: enables export to multiple 'part' files instead of just a single file.\n",
      "            Convenient for large datasets that take too long to store in a single file.\n",
      "            Use parts=-1 to instruct H2O to determine the optimal number of part files or\n",
      "            specify your desired maximum number of part files. Path needs to be a directory\n",
      "            when exporting to multiple files, also that directory must be empty.\n",
      "            Default is ``parts = 1``, which is to export to a single file.\n",
      "    \n",
      "    flow()\n",
      "        Open H2O Flow in your browser.\n",
      "    \n",
      "    frame(frame_id)\n",
      "        Retrieve metadata for an id that points to a Frame.\n",
      "        \n",
      "        :param frame_id: the key of a Frame in H2O.\n",
      "        \n",
      "        :returns: dict containing the frame meta-information.\n",
      "    \n",
      "    frames()\n",
      "        Retrieve all the Frames.\n",
      "        \n",
      "        :returns: Meta information on the frames\n",
      "    \n",
      "    get_frame(frame_id, **kwargs)\n",
      "        Obtain a handle to the frame in H2O with the frame_id key.\n",
      "        \n",
      "        :param str frame_id: id of the frame to retrieve.\n",
      "        :returns: an :class:`H2OFrame` object\n",
      "    \n",
      "    get_grid(grid_id)\n",
      "        Return the specified grid.\n",
      "        \n",
      "        :param grid_id: The grid identification in h2o\n",
      "        \n",
      "        :returns: an :class:`H2OGridSearch` instance.\n",
      "    \n",
      "    get_model(model_id)\n",
      "        Load a model from the server.\n",
      "        \n",
      "        :param model_id: The model identification in H2O\n",
      "        \n",
      "        :returns: Model object, a subclass of H2OEstimator\n",
      "    \n",
      "    get_timezone(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().timezone``.\n",
      "    \n",
      "    import_file(path=None, destination_frame=None, parse=True, header=0, sep=None, col_names=None, col_types=None, na_strings=None, pattern=None, skipped_columns=None)\n",
      "        Import a dataset that is already on the cluster.\n",
      "        \n",
      "        The path to the data must be a valid path for each node in the H2O cluster. If some node in the H2O cluster\n",
      "        cannot see the file, then an exception will be thrown by the H2O cluster. Does a parallel/distributed\n",
      "        multi-threaded pull of the data. The main difference between this method and :func:`upload_file` is that\n",
      "        the latter works with local files, whereas this method imports remote files (i.e. files local to the server).\n",
      "        If you running H2O server on your own maching, then both methods behave the same.\n",
      "        \n",
      "        :param path: path(s) specifying the location of the data to import or a path to a directory of files to import\n",
      "        :param destination_frame: The unique hex key assigned to the imported file. If none is given, a key will be\n",
      "            automatically generated.\n",
      "        :param parse: If True, the file should be parsed after import. If False, then a list is returned containing the file path.\n",
      "        :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n",
      "        :param sep: The field separator character. Values on each line of the file are separated by\n",
      "            this character. If not provided, the parser will automatically detect the separator.\n",
      "        :param col_names: A list of column names for the file.\n",
      "        :param col_types: A list of types or a dictionary of column names to types to specify whether columns\n",
      "            should be forced to a certain type upon import parsing. If a list, the types for elements that are\n",
      "            one will be guessed. The possible types a column may have are:\n",
      "        \n",
      "            - \"unknown\" - this will force the column to be parsed as all NA\n",
      "            - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n",
      "            - \"string\"  - force the column to be parsed as a string\n",
      "            - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n",
      "              data in the optimal manner.\n",
      "            - \"enum\"    - force the column to be parsed as a categorical column.\n",
      "            - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n",
      "              list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n",
      "              \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n",
      "              Times can also contain \"AM\" or \"PM\".\n",
      "        :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n",
      "            of column names to strings which are to be interpreted as missing values.\n",
      "        :param pattern: Character string containing a regular expression to match file(s) in the folder if `path` is a\n",
      "            directory.\n",
      "        :param skipped_columns: an integer list of column indices to skip and not parsed into the final frame from the import file.\n",
      "        \n",
      "        :returns: a new :class:`H2OFrame` instance.\n",
      "        \n",
      "        :examples:\n",
      "            >>> # Single file import\n",
      "            >>> iris = import_file(\"h2o-3/smalldata/iris.csv\")\n",
      "            >>> # Return all files in the folder iris/ matching the regex r\"iris_.*\\.csv\"\n",
      "            >>> iris_pattern = h2o.import_file(path = \"h2o-3/smalldata/iris\",\n",
      "            ...                                pattern = \"iris_.*\\.csv\")\n",
      "    \n",
      "    import_sql_select(connection_url, select_query, username, password, optimize=True, fetch_mode=None)\n",
      "        Import the SQL table that is the result of the specified SQL query to H2OFrame in memory.\n",
      "        \n",
      "        Creates a temporary SQL table from the specified sql_query.\n",
      "        Runs multiple SELECT SQL queries on the temporary table concurrently for parallel ingestion, then drops the table.\n",
      "        Be sure to start the h2o.jar in the terminal with your downloaded JDBC driver in the classpath::\n",
      "        \n",
      "          java -cp <path_to_h2o_jar>:<path_to_jdbc_driver_jar> water.H2OApp\n",
      "        \n",
      "        Also see h2o.import_sql_table. Currently supported SQL databases are MySQL, PostgreSQL, and MariaDB. Support\n",
      "        for Oracle 12g and Microsoft SQL Server is forthcoming.\n",
      "        \n",
      "        :param connection_url: URL of the SQL database connection as specified by the Java Database Connectivity (JDBC)\n",
      "            Driver. For example, \"jdbc:mysql://localhost:3306/menagerie?&useSSL=false\"\n",
      "        :param select_query: SQL query starting with `SELECT` that returns rows from one or more database tables.\n",
      "        :param username: username for SQL server\n",
      "        :param password: password for SQL server\n",
      "        :param optimize: DEPRECATED. Ignored - use fetch_mode instead. Optimize import of SQL table for faster imports.\n",
      "        :param fetch_mode: Set to DISTRIBUTED to enable distributed import. Set to SINGLE to force a sequential read by a single node\n",
      "            from the database.\n",
      "        \n",
      "        :returns: an :class:`H2OFrame` containing data of the specified SQL query.\n",
      "        \n",
      "        :examples:\n",
      "            >>> conn_url = \"jdbc:mysql://172.16.2.178:3306/ingestSQL?&useSSL=false\"\n",
      "            >>> select_query = \"SELECT bikeid from citibike20k\"\n",
      "            >>> username = \"root\"\n",
      "            >>> password = \"abc123\"\n",
      "            >>> my_citibike_data = h2o.import_sql_select(conn_url, select_query,\n",
      "            ...                                          username, password, fetch_mode)\n",
      "    \n",
      "    import_sql_table(connection_url, table, username, password, columns=None, optimize=True, fetch_mode=None)\n",
      "        Import SQL table to H2OFrame in memory.\n",
      "        \n",
      "        Assumes that the SQL table is not being updated and is stable.\n",
      "        Runs multiple SELECT SQL queries concurrently for parallel ingestion.\n",
      "        Be sure to start the h2o.jar in the terminal with your downloaded JDBC driver in the classpath::\n",
      "        \n",
      "            java -cp <path_to_h2o_jar>:<path_to_jdbc_driver_jar> water.H2OApp\n",
      "        \n",
      "        Also see :func:`import_sql_select`.\n",
      "        Currently supported SQL databases are MySQL, PostgreSQL, MariaDB, and Netezza. Support for Oracle 12g and Microsoft SQL\n",
      "        Server is forthcoming.\n",
      "        \n",
      "        :param connection_url: URL of the SQL database connection as specified by the Java Database Connectivity (JDBC)\n",
      "            Driver. For example, \"jdbc:mysql://localhost:3306/menagerie?&useSSL=false\"\n",
      "        :param table: name of SQL table\n",
      "        :param columns: a list of column names to import from SQL table. Default is to import all columns.\n",
      "        :param username: username for SQL server\n",
      "        :param password: password for SQL server\n",
      "        :param optimize: DEPRECATED. Ignored - use fetch_mode instead. Optimize import of SQL table for faster imports.\n",
      "        :param fetch_mode: Set to DISTRIBUTED to enable distributed import. Set to SINGLE to force a sequential read by a single node\n",
      "            from the database.\n",
      "        \n",
      "        :returns: an :class:`H2OFrame` containing data of the specified SQL table.\n",
      "        \n",
      "        :examples:\n",
      "            >>> conn_url = \"jdbc:mysql://172.16.2.178:3306/ingestSQL?&useSSL=false\"\n",
      "            >>> table = \"citibike20k\"\n",
      "            >>> username = \"root\"\n",
      "            >>> password = \"abc123\"\n",
      "            >>> my_citibike_data = h2o.import_sql_table(conn_url, table, username, password)\n",
      "    \n",
      "    init(url=None, ip=None, port=None, name=None, https=None, insecure=None, username=None, password=None, cookies=None, proxy=None, start_h2o=True, nthreads=-1, ice_root=None, log_dir=None, log_level=None, enable_assertions=True, max_mem_size=None, min_mem_size=None, strict_version_check=None, ignore_config=False, extra_classpath=None, jvm_custom_args=None, bind_to_localhost=True, **kwargs)\n",
      "        Attempt to connect to a local server, or if not successful start a new server and connect to it.\n",
      "        \n",
      "        :param url: Full URL of the server to connect to (can be used instead of `ip` + `port` + `https`).\n",
      "        :param ip: The ip address (or host name) of the server where H2O is running.\n",
      "        :param port: Port number that H2O service is listening to.\n",
      "        :param name: cloud name. If None while connecting to an existing cluster it will not check the cloud name.\n",
      "        If set then will connect only if the target cloud name matches. If no instance is found and decides to start a local\n",
      "        one then this will be used as the cloud name or a random one will be generated if set to None.\n",
      "        :param https: Set to True to connect via https:// instead of http://.\n",
      "        :param insecure: When using https, setting this to True will disable SSL certificates verification.\n",
      "        :param username: Username and\n",
      "        :param password: Password for basic authentication.\n",
      "        :param cookies: Cookie (or list of) to add to each request.\n",
      "        :param proxy: Proxy server address.\n",
      "        :param start_h2o: If False, do not attempt to start an h2o server when connection to an existing one failed.\n",
      "        :param nthreads: \"Number of threads\" option when launching a new h2o server.\n",
      "        :param ice_root: Directory for temporary files for the new h2o server.\n",
      "        :param log_dir: Directory for H2O logs to be stored if a new instance is started. Ignored if connecting to an existing node.\n",
      "        :param log_level: The logger level for H2O if a new instance is started. One of TRACE,DEBUG,INFO,WARN,ERRR,FATA.\n",
      "        Default is INFO. Ignored if connecting to an existing node.\n",
      "        :param enable_assertions: Enable assertions in Java for the new h2o server.\n",
      "        :param max_mem_size: Maximum memory to use for the new h2o server. Integer input will be evaluated as gigabytes.  Other units can be specified by passing in a string (e.g. \"160M\" for 160 megabytes).\n",
      "        :param min_mem_size: Minimum memory to use for the new h2o server. Integer input will be evaluated as gigabytes.  Other units can be specified by passing in a string (e.g. \"160M\" for 160 megabytes).\n",
      "        :param strict_version_check: If True, an error will be raised if the client and server versions don't match.\n",
      "        :param ignore_config: Indicates whether a processing of a .h2oconfig file should be conducted or not. Default value is False.\n",
      "        :param extra_classpath: List of paths to libraries that should be included on the Java classpath when starting H2O from Python.\n",
      "        :param kwargs: (all other deprecated attributes)\n",
      "        :param jvm_custom_args Customer, user-defined argument's for the JVM H2O is instantiated in. Ignored if there is an instance of H2O already running and the client connects to it.\n",
      "    \n",
      "    interaction(data, factors, pairwise, max_factors, min_occurrence, destination_frame=None)\n",
      "        Categorical Interaction Feature Creation in H2O.\n",
      "        \n",
      "        Creates a frame in H2O with n-th order interaction features between categorical columns, as specified by\n",
      "        the user.\n",
      "        \n",
      "        :param data: the H2OFrame that holds the target categorical columns.\n",
      "        :param factors: factor columns (either indices or column names).\n",
      "        :param pairwise: If True, create pairwise interactions between factors (otherwise create one\n",
      "            higher-order interaction). Only applicable if there are 3 or more factors.\n",
      "        :param max_factors: Max. number of factor levels in pair-wise interaction terms (if enforced, one extra\n",
      "            catch-all factor will be made).\n",
      "        :param min_occurrence: Min. occurrence threshold for factor levels in pair-wise interaction terms\n",
      "        :param destination_frame: a string indicating the destination key. If empty, this will be auto-generated by H2O.\n",
      "        \n",
      "        :returns: :class:`H2OFrame`\n",
      "    \n",
      "    is_expr_optimizations_enabled()\n",
      "    \n",
      "    lazy_import(path, pattern=None)\n",
      "        Import a single file or collection of files.\n",
      "        \n",
      "        :param path: A path to a data file (remote or local).\n",
      "        :param pattern: Character string containing a regular expression to match file(s) in the folder.\n",
      "        :returns: either a :class:`H2OFrame` with the content of the provided file, or a list of such frames if\n",
      "            importing multiple files.\n",
      "    \n",
      "    list_timezones(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().list_timezones()``.\n",
      "    \n",
      "    load_dataset(relative_path)\n",
      "        Imports a data file within the 'h2o_data' folder.\n",
      "    \n",
      "    load_model(path)\n",
      "        Load a saved H2O model from disk. (Note that ensemble binary models can now be loaded using this method.)\n",
      "        \n",
      "        :param path: the full path of the H2O Model to be imported.\n",
      "        \n",
      "        :returns: an :class:`H2OEstimator` object\n",
      "        \n",
      "        :examples:\n",
      "            >>> path = h2o.save_model(my_model, dir=my_path)\n",
      "            >>> h2o.load_model(path)\n",
      "    \n",
      "    log_and_echo(message=u'')\n",
      "        Log a message on the server-side logs.\n",
      "        \n",
      "        This is helpful when running several pieces of work one after the other on a single H2O\n",
      "        cluster and you want to make a notation in the H2O server side log where one piece of\n",
      "        work ends and the next piece of work begins.\n",
      "        \n",
      "        Sends a message to H2O for logging. Generally used for debugging purposes.\n",
      "        \n",
      "        :param message: message to write to the log.\n",
      "    \n",
      "    ls()\n",
      "        List keys on an H2O Cluster.\n",
      "    \n",
      "    make_metrics(predicted, actual, domain=None, distribution=None)\n",
      "        Create Model Metrics from predicted and actual values in H2O.\n",
      "        \n",
      "        :param H2OFrame predicted: an H2OFrame containing predictions.\n",
      "        :param H2OFrame actuals: an H2OFrame containing actual values.\n",
      "        :param domain: list of response factors for classification.\n",
      "        :param distribution: distribution for regression.\n",
      "    \n",
      "    mojo_predict_csv(input_csv_path, mojo_zip_path, output_csv_path=None, genmodel_jar_path=None, classpath=None, java_options=None, verbose=False)\n",
      "        MOJO scoring function to take a CSV file and use MOJO model as zip file to score.\n",
      "        \n",
      "        :param input_csv_path: Path to input CSV file.\n",
      "        :param mojo_zip_path: Path to MOJO zip downloaded from H2O.\n",
      "        :param output_csv_path: Optional, name of the output CSV file with computed predictions. If None (default), then\n",
      "            predictions will be saved as prediction.csv in the same folder as the MOJO zip.\n",
      "        :param genmodel_jar_path: Optional, path to genmodel jar file. If None (default) then the h2o-genmodel.jar in the same\n",
      "            folder as the MOJO zip will be used.\n",
      "        :param classpath: Optional, specifies custom user defined classpath which will be used when scoring. If None\n",
      "            (default) then the default classpath for this MOJO model will be used.\n",
      "        :param java_options: Optional, custom user defined options for Java. By default ``-Xmx4g -XX:ReservedCodeCacheSize=256m`` is used.\n",
      "        :param verbose: Optional, if True, then additional debug information will be printed. False by default.\n",
      "        :return: List of computed predictions\n",
      "    \n",
      "    mojo_predict_pandas(dataframe, mojo_zip_path, genmodel_jar_path=None, classpath=None, java_options=None, verbose=False)\n",
      "        MOJO scoring function to take a Pandas frame and use MOJO model as zip file to score.\n",
      "        \n",
      "        :param dataframe: Pandas frame to score.\n",
      "        :param mojo_zip_path: Path to MOJO zip downloaded from H2O.\n",
      "        :param genmodel_jar_path: Optional, path to genmodel jar file. If None (default) then the h2o-genmodel.jar in the same\n",
      "            folder as the MOJO zip will be used.\n",
      "        :param classpath: Optional, specifies custom user defined classpath which will be used when scoring. If None\n",
      "            (default) then the default classpath for this MOJO model will be used.\n",
      "        :param java_options: Optional, custom user defined options for Java. By default ``-Xmx4g`` is used.\n",
      "        :param verbose: Optional, if True, then additional debug information will be printed. False by default.\n",
      "        :return: Pandas frame with predictions\n",
      "    \n",
      "    network_test(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().network_test()``.\n",
      "    \n",
      "    no_progress()\n",
      "        Disable the progress bar from flushing to stdout.\n",
      "        \n",
      "        The completed progress bar is printed when a job is complete so as to demarcate a log file.\n",
      "    \n",
      "    parse_raw(setup, id=None, first_line_is_header=0)\n",
      "        Parse dataset using the parse setup structure.\n",
      "        \n",
      "        :param setup: Result of ``h2o.parse_setup()``\n",
      "        :param id: an id for the frame.\n",
      "        :param first_line_is_header: -1, 0, 1 if the first line is to be used as the header\n",
      "        \n",
      "        :returns: an :class:`H2OFrame` object.\n",
      "    \n",
      "    parse_setup(raw_frames, destination_frame=None, header=0, separator=None, column_names=None, column_types=None, na_strings=None, skipped_columns=None)\n",
      "        Retrieve H2O's best guess as to what the structure of the data file is.\n",
      "        \n",
      "        During parse setup, the H2O cluster will make several guesses about the attributes of\n",
      "        the data. This method allows a user to perform corrective measures by updating the\n",
      "        returning dictionary from this method. This dictionary is then fed into `parse_raw` to\n",
      "        produce the H2OFrame instance.\n",
      "        \n",
      "        :param raw_frames: a collection of imported file frames\n",
      "        :param destination_frame: The unique hex key assigned to the imported file. If none is given, a key will\n",
      "            automatically be generated.\n",
      "        :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n",
      "        :param separator: The field separator character. Values on each line of the file are separated by\n",
      "            this character. If not provided, the parser will automatically detect the separator.\n",
      "        :param column_names: A list of column names for the file. If skipped_columns are specified, only list column names\n",
      "             of columns that are not skipped.\n",
      "        :param column_types: A list of types or a dictionary of column names to types to specify whether columns\n",
      "            should be forced to a certain type upon import parsing. If a list, the types for elements that are\n",
      "            one will be guessed. If skipped_columns are specified, only list column types of columns that are not skipped.\n",
      "            The possible types a column may have are:\n",
      "        \n",
      "            - \"unknown\" - this will force the column to be parsed as all NA\n",
      "            - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n",
      "            - \"string\"  - force the column to be parsed as a string\n",
      "            - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n",
      "              data in the optimal manner.\n",
      "            - \"enum\"    - force the column to be parsed as a categorical column.\n",
      "            - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n",
      "              list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n",
      "              \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n",
      "              Times can also contain \"AM\" or \"PM\".\n",
      "        \n",
      "        :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n",
      "            of column names to strings which are to be interpreted as missing values.\n",
      "        :param skipped_columns: an integer lists of column indices to skip and not parsed into the final frame from the import file.\n",
      "        \n",
      "        :returns: a dictionary containing parse parameters guessed by the H2O backend.\n",
      "    \n",
      "    rapids(expr)\n",
      "        Execute a Rapids expression.\n",
      "        \n",
      "        :param expr: The rapids expression (ascii string).\n",
      "        \n",
      "        :returns: The JSON response (as a python dictionary) of the Rapids execution.\n",
      "    \n",
      "    remove(x)\n",
      "        Remove object(s) from H2O.\n",
      "        \n",
      "        :param x: H2OFrame, H2OEstimator, or string, or a list of those things: the object(s) or unique id(s)\n",
      "            pointing to the object(s) to be removed.\n",
      "    \n",
      "    remove_all()\n",
      "        Remove all objects from H2O.\n",
      "    \n",
      "    save_model(model, path=u'', force=False)\n",
      "        Save an H2O Model object to disk. (Note that ensemble binary models can now be saved using this method.)\n",
      "        \n",
      "        :param model: The model object to save.\n",
      "        :param path: a path to save the model at (hdfs, s3, local)\n",
      "        :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      "        \n",
      "        :returns: the path of the saved model\n",
      "        \n",
      "        :examples:\n",
      "            >>> path = h2o.save_model(my_model, dir=my_path)\n",
      "    \n",
      "    set_timezone(*args, **kwargs)\n",
      "        Deprecated, set ``h2o.cluster().timezone`` instead.\n",
      "    \n",
      "    show_progress()\n",
      "        Enable the progress bar (it is enabled by default).\n",
      "    \n",
      "    shutdown(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().shutdown()``.\n",
      "    \n",
      "    upload_custom_metric(func, func_file=u'metrics.py', func_name=None, class_name=None, source_provider=None)\n",
      "        Upload given metrics function into H2O cluster.\n",
      "        \n",
      "        The metrics can have different representation:\n",
      "          - method\n",
      "          - class: needs to inherit from water.udf.CFunc2 and implement method apply(actual, predict)\n",
      "          returning double\n",
      "          - string: the same as in class case, but the class is given as a string\n",
      "        \n",
      "        :param func:  metrics representation: string, class, function\n",
      "        :param func_file:  internal name of file to save given metrics representation\n",
      "        :param func_name:  name for h2o key under which the given metric is saved\n",
      "        :param class_name: name of class wrapping the metrics function\n",
      "        :param source_provider: a function which provides a source code for given function\n",
      "        :return: reference to uploaded metrics function\n",
      "    \n",
      "    upload_file(path, destination_frame=None, header=0, sep=None, col_names=None, col_types=None, na_strings=None, skipped_columns=None)\n",
      "        Upload a dataset from the provided local path to the H2O cluster.\n",
      "        \n",
      "        Does a single-threaded push to H2O. Also see :meth:`import_file`.\n",
      "        \n",
      "        :param path: A path specifying the location of the data to upload.\n",
      "        :param destination_frame:  The unique hex key assigned to the imported file. If none is given, a key will\n",
      "            be automatically generated.\n",
      "        :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n",
      "        :param sep: The field separator character. Values on each line of the file are separated by\n",
      "            this character. If not provided, the parser will automatically detect the separator.\n",
      "        :param col_names: A list of column names for the file.\n",
      "        :param col_types: A list of types or a dictionary of column names to types to specify whether columns\n",
      "            should be forced to a certain type upon import parsing. If a list, the types for elements that are\n",
      "            one will be guessed. The possible types a column may have are:\n",
      "        \n",
      "            - \"unknown\" - this will force the column to be parsed as all NA\n",
      "            - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n",
      "            - \"string\"  - force the column to be parsed as a string\n",
      "            - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n",
      "              data in the optimal manner.\n",
      "            - \"enum\"    - force the column to be parsed as a categorical column.\n",
      "            - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n",
      "              list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n",
      "              \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n",
      "              Times can also contain \"AM\" or \"PM\".\n",
      "        :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n",
      "            of column names to strings which are to be interpreted as missing values.\n",
      "        :param skipped_columns: an integer lists of column indices to skip and not parsed into the final frame from the import file.\n",
      "        \n",
      "        :returns: a new :class:`H2OFrame` instance.\n",
      "        \n",
      "        :examples:\n",
      "            >>> frame = h2o.upload_file(\"/path/to/local/data\")\n",
      "\n",
      "DATA\n",
      "    __all__ = (u'connect', u'init', u'api', u'connection', u'upload_file',...\n",
      "    __buildinfo__ = u\"versionFromGradle='3.22.0',projectVersion='3.2...led...\n",
      "    __version__ = u'3.22.0.2'\n",
      "\n",
      "VERSION\n",
      "    3.22.0.2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://127.0.0.1:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>1 min 16 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>25 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_shiva_8791f9</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>8 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.15 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O cluster uptime:         1 min 16 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.2\n",
       "H2O cluster version age:    25 days\n",
       "H2O cluster name:           H2O_from_python_shiva_8791f9\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    8 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Algos, AutoML, Core V3, Core V4\n",
       "Python version:             2.7.15 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(ip=\"127.0.0.1\", port=54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H2Os Deep Learning is based on a multi-layer feedforward artificial neural network that is trained with stochastic gradient descent using back-propagation. The network can contain a large number of hidden layers consisting of neurons with tanh, rectifier, and maxout activation functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline                         \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from h2o.estimators.deeplearning import H2OAutoEncoderEstimator, H2ODeepLearningEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocesing\n",
    "\n",
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "loan_csv = \"https://raw.githubusercontent.com/h2oai/app-consumer-loan/master/data/loan.csv\"\n",
    "data_loan = h2o.import_file(loan_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163987, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to train a binary classification model, we must ensure that the response is coded as a factor. If the response is 0/1, H2O will assume it's numeric, which means that H2O will train a regression model instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '1']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loan['bad_loan'] = data_loan['bad_loan'].asfactor()  #encode the binary repsonse as a factor\n",
    "data_loan['bad_loan'].levels()  #optional: after encoding, this shows the two factor levels, '0' and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data\n",
    "\n",
    "Next, we partition the data into training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = data_loan.split_frame(ratios=[0.7, 0.15], seed=1)  \n",
    "\n",
    "train = splits[0]\n",
    "valid = splits[1]\n",
    "test = splits[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that split_frame() uses approximate splitting not exact splitting (for efficiency), so these are not exactly 70%, 15% and 15% of the total rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114908\n",
      "24498\n",
      "24581\n"
     ]
    }
   ],
   "source": [
    "print(train.nrow)\n",
    "print(valid.nrow)\n",
    "print(test.nrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify response and predictor variables\n",
    "\n",
    "In H2O, we use y to designate the response variable and x to designate the list of predictor columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'bad_loan'\n",
    "x = list(data_loan.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'loan_amnt',\n",
       " u'term',\n",
       " u'emp_length',\n",
       " u'home_ownership',\n",
       " u'annual_inc',\n",
       " u'purpose',\n",
       " u'addr_state',\n",
       " u'dti',\n",
       " u'delinq_2yrs',\n",
       " u'revol_util',\n",
       " u'total_acc',\n",
       " u'longest_credit_length',\n",
       " u'verification_status']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.remove(y)  #remove the response\n",
    "x.remove('int_rate')  #remove the interest rate column because it's correlated with the outcome\n",
    "# List of predictor columns\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H2O Machine Learning\n",
    "\n",
    "Now that we have prepared the data, we can train some models. We will start by training a single model from each of the H2O supervised algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest (RF)\n",
    "\n",
    "\n",
    "H2O's Random Forest (RF) is implements a distributed version of the standard Random Forest algorithm and variable importance measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import H2O RF:\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a default RF\n",
    "\n",
    "First we will train a basic Random Forest model with default parameters. Random Forest will infer the response distribution from the response encoding. A seed is required for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RF estimator:\n",
    "\n",
    "rf_fit1 = H2ORandomForestEstimator(model_id='rf_fit1', seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "rf_fit1.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an RF with more trees\n",
    "\n",
    "Next we will increase the number of trees used in the forest by setting ntrees = 100. The default number of trees in an H2O Random Forest is 50, so this RF will be twice as big as the default. Usually increasing the number of trees in an RF will increase performance as well. Unlike Gradient Boosting Machines (GBMs), Random Forests are fairly resistant (although not free from) overfitting by increasing the number of trees. See the GBM example below for additional guidance on preventing overfitting using H2O's early stopping functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "rf_fit2 = H2ORandomForestEstimator(model_id='rf_fit2', ntrees=100, seed=1)\n",
    "rf_fit2.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.663460943045\n",
      "0.669285050822\n"
     ]
    }
   ],
   "source": [
    "rf_perf1 = rf_fit1.model_performance(test)\n",
    "rf_perf2 = rf_fit2.model_performance(test)\n",
    "print(rf_perf1.auc())\n",
    "print(rf_perf2.auc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validate performance\n",
    "\n",
    "Rather than using held-out test set to evaluate model performance, a user may wish to estimate model performance using cross-validation. Using the RF algorithm (with default model parameters) as an example, we demonstrate how to perform k-fold cross-validation using H2O. No custom code or loops are required, you simply specify the number of desired folds in the nfolds argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are not going to use a test set here, we can use the original (full) dataset, which we called data rather than the subsampled train dataset. Note that this will take approximately k (nfolds) times longer than training a single RF model, since it will train k models in the cross-validation process (trained on n(k-1)/k rows), in addition to the final model trained on the full training_frame dataset with n rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_fit3 = H2ORandomForestEstimator(model_id='rf_fit3', seed=1, nfolds=5)\n",
    "rf_fit3.train(x=x, y=y, training_frame=data_loan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the cross-validated AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66361117109\n"
     ]
    }
   ],
   "source": [
    "print rf_fit3.auc(xval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the cross-validated AUC is slighly higher than the test set performance we estimated for rf_fit1, and this is likely due to the fact that we trained on more data (n rows) than we did while using train as the training set (0.75*n rows) in rf_fit1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
